{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
        "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Databricks Platform\n",
        "Demonstrate basic functionality and identify terms related to working in the Databricks workspace.\n",
        "\n",
        "##### Objectives\n",
        "1. Create a new cell\n",
        "1. Execute code in multiple languages\n",
        "1. Create markdown cells\n",
        "1. Read data from DBFS (Databricks File System)\n",
        "1. Visualize data\n",
        "1. Install libraries\n",
        "\n",
        "##### Databricks Notebook Utilities\n",
        "- Example <a href=\"https://docs.databricks.com/notebooks/notebooks-use.html#language-magic\" target=\"_blank\">magic commands</a>: **`%python`**, **`%sql`**, **`%md`**, **`%fs`**, **`%sh`**, **`%pip`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n",
        "Run classroom setup to copy Databricks training datasets into your environment.\n",
        "\n",
        "Use the **`%run`** magic command to run another notebook within a notebook\n",
        "\n",
        "To run the notebook cell below click on the cell containing the `%run` command, this selects the cell, and then push `Shift + Enter` on your keyboard. Cells can also be run by clicking the arrow in the top right corner of the cell (the arrow will appear when hovering your mouse over the cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %run ../Includes/Classroom-Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a new Cell\n",
        "Notebook cells can be created by clicking the \"`+`\" button that appears when you hover your mouse between two cells, or by using keyboard shortcuts. To use the keyboard shortcuts select any cell and press `A` to insert a cell above the selected cell, or `B` to insert a cell below the selected cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try creating a cell below me! Click on my cell (not in the text area itself) and then press `B`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute code in multiple languages\n",
        "Databricks notbooks support 4 different languages : <a href=\"https://www.python.org/\" target=\"_blank\">Python</a>, <a href=\"https://www.scala-lang.org/\" target=\"_blank\">Scala</a>, <a href=\"https://en.wikipedia.org/wiki/SQL\" target=\"_blank\">SQL</a>, and <a href=\"https://www.r-project.org/\" target=\"_blank\">R</a>. Upon creation of a notebook you'll set a default language for the cells in the notebook to use. The default language of the notebook is displayed in the upper left of your window, to the right of the notebook name.\n",
        "\n",
        "* Each notebook specifies a default language, in this case **Python**.\n",
        "* Run the cell below using one of the following options:\n",
        "  * **CTRL+ENTER** or **CMD+RETURN**\n",
        "  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n",
        "  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>\n",
        "\n",
        "The below cell shows an example of a python command executing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Run default language\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But you can also use non-default languages in your notebooks as well! Try running languages specified by their language magic commands: **`%python`**, **`%scala`**, **`%sql`**, **`%r`**.\n",
        "\n",
        "Below are examples of using magic commands to execute code in **python** and **sql**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %python\n",
        "# MAGIC print(\"Run python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %sql\n",
        "# MAGIC select \"Run SQL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create documentation cells\n",
        "Render cell as <a href=\"https://www.markdownguide.org/cheat-sheet/\" target=\"_blank\">Markdown</a> using the magic command: **`%md`**\n",
        "\n",
        "Below are some examples of how you can use Markdown to format documentation. Click this cell and press **`Enter`** to view the underlying Markdown syntax.\n",
        "\n",
        "# Heading 1\n",
        "### Heading 3\n",
        "> block quote\n",
        "\n",
        "1. **bold**\n",
        "2. *italicized*\n",
        "3. ~~strikethrough~~\n",
        "\n",
        "---\n",
        "\n",
        "- <a href=\"https://www.markdownguide.org/cheat-sheet/\" target=\"_blank\">link</a>\n",
        "- `code`\n",
        "\n",
        "```\n",
        "{\n",
        "  \"message\": \"This is a code block\",\n",
        "  \"method\": \"https://www.markdownguide.org/extended-syntax/#fenced-code-blocks\",\n",
        "  \"alternative\": \"https://www.markdownguide.org/basic-syntax/#code-blocks\"\n",
        "}\n",
        "```\n",
        "\n",
        "![Spark Logo](https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png)\n",
        "\n",
        "| Element         | Markdown Syntax |\n",
        "|-----------------|-----------------|\n",
        "| Heading         | `#H1` `##H2` `###H3` `#### H4` `##### H5` `###### H6` |\n",
        "| Block quote     | `> blockquote` |\n",
        "| Bold            | `**bold**` |\n",
        "| Italic          | `*italicized*` |\n",
        "| Strikethrough   | `~~strikethrough~~` |\n",
        "| Horizontal Rule | `---` |\n",
        "| Code            | ``` `code` ``` |\n",
        "| Link            | `[text](https://www.example.com)` |\n",
        "| Image           | `![alt text](image.jpg)`|\n",
        "| Ordered List    | `1. First items` <br> `2. Second Item` <br> `3. Third Item` |\n",
        "| Unordered List  | `- First items` <br> `- Second Item` <br> `- Third Item` |\n",
        "| Code Block      | ```` ``` ```` <br> `code block` <br> ```` ``` ````|\n",
        "| Table           |<code> &#124; col &#124; col &#124; col &#124; </code> <br> <code> &#124;---&#124;---&#124;---&#124; </code> <br> <code> &#124; val &#124; val &#124; val &#124; </code> <br> <code> &#124; val &#124; val &#124; val &#124; </code> <br>|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading data\n",
        "When you ran the **Setup** cell at the top of the notebook, some variables were created for you. One of the variables is `DA.paths.datasets` which is the path to datasets which will be used during this course.\n",
        "\n",
        "One such dataset is located at **`{DA.paths.datasets}/news/labelled_newscatcher_dataset.csv`**. Let's use `pandas` to read that csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the location of the csv file\n",
        "csv_location = f\"../../datasets/news/labelled_newscatcher_dataset.csv\"\n",
        "# Read the dataset\n",
        "newscatcher = pd.read_csv(csv_location, sep=\";\")\n",
        "# Display the datset\n",
        "newscatcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use `matplotlib` to plot aggregate data from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count how many articles exist per topic\n",
        "newscatcher_counts_by_topic = (\n",
        "    newscatcher\n",
        "    .loc[:,[\"topic\",\"title\"]]\n",
        "    .groupby(\"topic\")\n",
        "    .agg(\"count\")\n",
        "    .reset_index(drop=False)\n",
        ")\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(newscatcher_counts_by_topic[\"topic\"],height=newscatcher_counts_by_topic[\"title\"])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `display()` command will pretty-print a large variety of data types, including Apache Spark DataFrames or Pandas DataFrames.\n",
        "\n",
        "It will also allow you to make visualizations without writing additional code. For example, after executing the below command click the `+` icon in the results to add a Visualization. Select the **Bar** visualization type and click \"Save\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(newscatcher_counts_by_topic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Databricks Runtime (DBR) environments come with many pre-installed libraries (for example, <a href=\"https://docs.databricks.com/release-notes/runtime/13.1ml.html#python-libraries-on-cpu-clusters\"  target=\"_blank\">DBR 13.1 python libraries</a>), but sometimes you'll want to install some additional ones.\n",
        "\n",
        "Additional libraries can be installed directly onto your cluster in the **Compute** tab, or you can install them with a scope specific to your individual notebook using the `%pip` magic command.\n",
        "\n",
        "Because sometimes you'll need to restart your python kernel after installing a new library via `%pip` it's considered best practice to put all `%pip` commands at the very top of your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAGIC %pip install nlptest==1.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can import the newly installed `nlptest` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nlptest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning More\n",
        "We like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\n",
        "* <a href=\"https://docs.databricks.com/user-guide/index.html\" target=\"_blank\">User Guide</a>\n",
        "* <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\n",
        "* <a href=\"https://docs.databricks.com/administration-guide/index.html\" target=\"_blank\">Administration Guide</a>\n",
        "* <a href=\"https://docs.databricks.com/release-notes/index.html\" target=\"_blank\">Release Notes</a>\n",
        "* <a href=\"https://docs.databricks.com/\" target=\"_blank\">And much more!</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-sandbox\n",
        "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
        "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
        "<br/>\n",
        "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
