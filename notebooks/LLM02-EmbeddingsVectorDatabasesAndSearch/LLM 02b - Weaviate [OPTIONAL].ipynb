{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-sandbox\n",
        "# MAGIC\n",
        "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
        "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Weaviate\n",
        "# MAGIC\n",
        "In this notebook, we will use Weaviate as our vector database. We will then write the embedding vectors out to Weaviate and query for similar documents. Weaviate provides customization options, such as to incorporate Product Quantization or not (refer [here](https://weaviate.io/developers/weaviate/concepts/vector-index#hnsw-with-product-quantizationpq)). \n",
        "# MAGIC\n",
        "[Zilliz](https://zilliz.com/) has an enterprise offering for Weaviate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library pre-requisites\n",
        "# MAGIC\n",
        "- weaviate-client\n",
        "  - pip install below\n",
        "- Spark connector jar file\n",
        "  - **IMPORTANT!!** Since we will be interacting with Spark by writing a Spark dataframe out to Weaviate, we need a Spark Connector.\n",
        "  - [Download the Spark connector jar file](https://github.com/weaviate/spark-connector#download-jar-from-github) and [upload to your Databricks cluster](https://github.com/weaviate/spark-connector#using-the-jar-in-databricks).\n",
        "# MAGIC\n",
        "# MAGIC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MAGIC %pip install weaviate-client==3.19.1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classroom Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MAGIC %run ../Includes/Classroom-Setup"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weaviate\n",
        "# MAGIC\n",
        "[Weaviate](https://weaviate.io/) is an open-source persistent and fault-tolerant [vector database](https://weaviate.io/developers/weaviate/concepts/storage). It integrates with a variety of tools, including OpenAI and Hugging Face Transformers. You can refer to their [documentation here](https://weaviate.io/developers/weaviate/quickstart).\n",
        "# MAGIC\n",
        "### Setting up your Weaviate Network\n",
        "# MAGIC\n",
        "Before we could proceed, you need your own Weaviate Network. To start your own network, visit the [homepage](https://weaviate.io/). \n",
        "# MAGIC\n",
        "Step 1: Click on `Start Free` \n",
        "# MAGIC\n",
        "<img src=\"https://files.training.databricks.com/images/weaviate_homepage.png\" width=500>\n",
        "# MAGIC\n",
        "Step 2: You will be brought to this [Console page](https://console.weaviate.cloud/). If this is your first time using Weaviate, click `Register here` and pass in your credentials.\n",
        "# MAGIC\n",
        "<img src=\"https://files.training.databricks.com/images/weaviate_register.png\" width=500>\n",
        "# MAGIC\n",
        "Step 3: Click on `Create cluster` and select `Free sandbox`. Provide your cluster name. For simplicity, we will toggle `enable authentication` to be `No`. Then, hit `Create`. \n",
        "# MAGIC\n",
        "<img src=\"https://files.training.databricks.com/images/weaviate_create_cluster.png\" width=900>\n",
        "# MAGIC\n",
        "Step 4: Click on `Details` and copy the `Cluster URL` and paste in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use embeddings from OpenAI,  so we will need a token from OpenAI API\n",
        "# MAGIC\n",
        "Steps:\n",
        "1. You need to [create an account](https://platform.openai.com/signup) on OpenAI. \n",
        "2. Generate an OpenAI [API key here](https://platform.openai.com/account/api-keys). \n",
        "# MAGIC\n",
        "Note: OpenAI does not have a free option, but it gives you $5 as credit. Once you have exhausted your $5 credit, you will need to add your payment method. You will be [charged per token usage](https://openai.com/pricing). **IMPORTANT**: It's crucial that you keep your OpenAI API key to yourself. If others have access to your OpenAI key, they will be able to charge their usage to your account! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<FILL IN>\"\n",
        "os.environ[\"WEAVIATE_NETWORK\"] = \"<FILL IN>\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "weaviate_network = os.environ[\"WEAVIATE_NETWORK\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import weaviate\n",
        "\n",
        "client = weaviate.Client(\n",
        "    weaviate_network, additional_headers={\"X-OpenAI-Api-Key\": openai.api_key}\n",
        ")\n",
        "client.is_ready()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n",
        "# MAGIC\n",
        "# MAGIC\n",
        "In this section, we are going to use the data on <a href=\"https://newscatcherapi.com/\" target=\"_blank\">news topics collected by the NewsCatcher team</a>, who collects and indexes news articles and release them to the open-source community. The dataset can be downloaded from <a href=\"https://www.kaggle.com/kotartemiy/topic-labeled-news-dataset\" target=\"_blank\">Kaggle</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = (\n",
        "    spark.read.option(\"header\", True)\n",
        "    .option(\"sep\", \";\")\n",
        "    .format(\"csv\")\n",
        "    .load(\n",
        "        f\"{DA.paths.datasets}/news/labelled_newscatcher_dataset.csv\".replace(\n",
        "            \"/dbfs\", \"dbfs:\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "display(df)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to store this dataset in the Weaviate database. To do that, we first need to define a schema. A schema is where we define classes, class properties, data types, and vectorizer modules we would like to use. \n",
        "# MAGIC\n",
        "In the schema below, notice that:\n",
        "# MAGIC\n",
        "- We capitalize the first letter of `class_name`. This is Weaviate's rule. \n",
        "- We specify data types within `properties`\n",
        "- We use `text2vec-openai` as the vectorizer. \n",
        "  - You can also choose to upload your own vectors (refer to [docs here](https://weaviate.io/developers/weaviate/api/rest/objects#with-a-custom-vector)) or create a class without any vectors (but we won't be able to perform similarity search after).\n",
        "# MAGIC\n",
        "[Reference documentation here](https://weaviate.io/developers/weaviate/tutorials/schema)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class_name = \"News\"\n",
        "class_obj = {\n",
        "    \"class\": class_name,\n",
        "    \"description\": \"News topics collected by NewsCatcher\",\n",
        "    \"properties\": [\n",
        "        {\"name\": \"topic\", \"dataType\": [\"string\"]},\n",
        "        {\"name\": \"link\", \"dataType\": [\"string\"]},\n",
        "        {\"name\": \"domain\", \"dataType\": [\"string\"]},\n",
        "        {\"name\": \"published_date\", \"dataType\": [\"string\"]},\n",
        "        {\"name\": \"title\", \"dataType\": [\"string\"]},\n",
        "        {\"name\": \"lang\", \"dataType\": [\"string\"]},\n",
        "    ],\n",
        "    \"vectorizer\": \"text2vec-openai\",\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If the class exists before, we will delete it first\n",
        "if client.schema.exists(class_name):\n",
        "    print(\"Deleting existing class...\")\n",
        "    client.schema.delete_class(class_name)\n",
        "\n",
        "print(f\"Creating class: '{class_name}'\")\n",
        "client.schema.create_class(class_obj)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are curious what the schema looks like for your class, run the following command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(client.schema.get(class_name), indent=4))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the class is created, we are going to write our dataframe to the class. \n",
        "# MAGIC\n",
        "**IMPORTANT!!** Since we are writing a Spark DataFrame out, we need a Spark Connector to Weaviate. You need to [download the Spark connector jar file](https://github.com/weaviate/spark-connector#download-jar-from-github) and [upload to your Databricks cluster](https://github.com/weaviate/spark-connector#using-the-jar-in-databricks) before running the next cell. If you do not do this, the next cell *will fail*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    df.limit(100)\n",
        "    .write.format(\"io.weaviate.spark.Weaviate\")\n",
        "    .option(\"scheme\", \"http\")\n",
        "    .option(\"host\", weaviate_network.split(\"https://\")[1])\n",
        "    .option(\"header:X-OpenAI-Api-Key\", openai.api_key)\n",
        "    .option(\"className\", class_name)\n",
        "    .mode(\"append\")\n",
        "    .save()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if the data is indeed populated. You can run either the following command or go to \n",
        "`https://{insert_your_cluster_url_here}/v1/objects` \n",
        "# MAGIC\n",
        "You should be able to see the data records, rather than null objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client.query.get(\"News\", [\"topic\"]).do()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yay! Looks like the data is populated. We can proceed further and do a query search. We are going to search for any news titles related to `locusts`. Additionally, we are going to add a filter statement, where the topic of the news has to be `SCIENCE`. Notice that we don't have to carry out the step of converting `locusts` into embeddings ourselves because we have included a vectorizer within the class earlier on.\n",
        "# MAGIC\n",
        "We will use `with_near_text` to specify the text we would like to query similar titles for. By default, Weaviate uses cosine distance to determine similar objects. Refer to [distance documentation here](https://weaviate.io/developers/weaviate/config-refs/distances#available-distance-metrics)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "where_filter = {\n",
        "    \"path\": [\"topic\"],\n",
        "    \"operator\": \"Equal\",\n",
        "    \"valueString\": \"SCIENCE\",\n",
        "}\n",
        "\n",
        "# We are going to search for any titles related to locusts\n",
        "near_text = {\"concepts\": \"locust\"}\n",
        "(\n",
        "    client.query.get(class_name, [\"topic\", \"domain\", \"title\"])\n",
        "    .with_where(where_filter)\n",
        "    .with_near_text(near_text)\n",
        "    .with_limit(2)\n",
        "    .do()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, if you wish to supply your own embeddings at query time, you can do that too. Since embeddings are vectors, we will use `with_near_vector` instead.\n",
        "# MAGIC\n",
        "In the code block below, we additionally introduce a `distance` parameter. The lower the distance score is, the closer the vectors are to each other. Read more about the distance thresholds [here](https://weaviate.io/developers/weaviate/config-refs/distances#available-distance-metrics)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import openai\n",
        "\n",
        "model = \"text-embedding-ada-002\"\n",
        "openai_object = openai.Embedding.create(input=[\"locusts\"], model=model)\n",
        "\n",
        "openai_embedding = openai_object[\"data\"][0][\"embedding\"]\n",
        "\n",
        "(\n",
        "    client.query.get(\"News\", [\"topic\", \"domain\", \"title\"])\n",
        "    .with_where(where_filter)\n",
        "    .with_near_vector(\n",
        "        {\n",
        "            \"vector\": openai_embedding,\n",
        "            \"distance\": 0.7,  # this sets a threshold for distance metric\n",
        "        }\n",
        "    )\n",
        "    .with_limit(2)\n",
        "    .do()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-sandbox\n",
        "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
        "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
        "<br/>\n",
        "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}